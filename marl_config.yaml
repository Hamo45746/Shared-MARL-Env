env: custom_multi_agent_env
env_config:
  config_path: "config.yaml"
  ae_folder_path: "/media/rppl/T7 Shield/METR4911/TA_autoencoder_h5_data/AE_save_06_09"

num_workers: 1
framework: torch
lr: 0.0003
train_batch_size: 400
sgd_minibatch_size: 32
num_sgd_iter: 3
rollout_fragment_length: 45
sample_timeout_s: 300
batch_mode: truncate_episodes
num_gpus: 1

model:
  fcnet_hiddens: [256, 256]
  fcnet_activation: relu

local_dir: "./custom_ray_results"

multiagent:
  policies:
    policy_0:
      - None
      - Box
      - [-inf, inf]
      - [1280]  # Flattened observation space
      - {}  # Modify action space if necessary
    policy_1:
      - None
      - Box
      - [-inf, inf]
      - [1280]  # Flattened observation space
      - {}
    policy_2:
      - None
      - Box
      - [-inf, inf]
      - [1280]  # Flattened observation space
      - {}
    policy_3:
      - None
      - Box
      - [-inf, inf]
      - [1280]  # Flattened observation space
      - {}
    policy_4:
      - None
      - Box
      - [-inf, inf]
      - [1280]  # Flattened observation space
      - {}
    policy_5:
      - None
      - Box
      - [-inf, inf]
      - [1280]  # Flattened observation space
      - {}
    policy_6:
      - None
      - Box
      - [-inf, inf]
      - [1280]  # Flattened observation space
      - {}
    policy_7:
      - None
      - Box
      - [-inf, inf]
      - [1280]  # Flattened observation space
      - {}
    policy_8:
      - None
      - Box
      - [-inf, inf]
      - [1280]  # Flattened observation space
      - {}
    policy_9:
      - None
      - Box
      - [-inf, inf]
      - [1280]  # Flattened observation space
      - {}

evaluation_interval: 10
evaluation_duration: 5
evaluation_num_workers: 1
evaluation_config:
  explore: false

checkpoint_freq: 50
checkpoint_at_end: true
