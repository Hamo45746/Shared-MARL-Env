# Configuration for MARL Environment
grid_size:
  #X: 100         # Width of the grid - UNNEEDED - get from map
  #Y: 177        # Height of the grid - UNNEEDED - get from map
  D: 4           # Number of layers in the grid (e.g., environment, targets, jammers, agent positions)

pixel_scale: 4 #Going down reduces the pixel_size, which reduces the map
map_scale: 0.18 #Going up makes to map larger
real_world_pixel_scale: 7 #what size in meters one pixles is in the real world

obs_range: 17 #13
comm_range: 40 #10
#agent_type: 'discrete'
agent_type: 'continuous'
#agent_type: 'task_allocation'
use_task_allocation_with_continuous: false
using_goals: false #Change this to use or not use goals 

map_path: 'maps/city_image_1.npy'
#map_path: 'maps/city_image_4.npy'
#map_path: 'maps/city_image_2.npy'
#map_path: 'maps/city_image_3.npy'
#map_path: 'maps/city_image_5.npy'

n_agents: 5
n_targets: 20
n_jammers: 5
jamming_radius: 20 #This is radius, in comparison to comms_range. That is why it is a smaller value then comms_range, but looks bigger relitivly.  

seed: 20

# This is for testing purposes
# agent_positions:
#  - [17, 39]
#  - [16, 17]
#  - [17, 37]
#  - [15, 13]
#  - [18, 19]

agent_positions:
 - [80, 120]
 - [81, 118]
 - [82, 119]
 - [79, 122]
 - [77, 121]

jammer_discovery_reward: 50
target_discovery_reward: 100
tracking_reward: 10
destruction_reward: 300
movement_penalty: -1
exploration_reward: 5