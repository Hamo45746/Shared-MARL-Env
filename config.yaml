# Configuration for MARL Environment
grid_size:
  #X: 100         # Width of the grid - UNNEEDED - get from map
  #Y: 177        # Height of the grid - UNNEEDED - get from map
  D: 4           # Number of layers in the grid (e.g., map, targets, jammers, agents)

# Keep these two constant now - Autoencoder trained on this input size
pixel_scale: 4 #Going down reduces the pixel_size, which reduces the map
map_scale: 0.18 #Going up makes to map larger

obs_range: 17 #13
comm_range: 40 #10
# agent_type: 'discrete'
# agent_type: 'continuous'
agent_type: 'task_allocation'

map_path: 'city_image_1.npy'
#map_path: 'city_image_2.npy'
#map_path: 'city_image_3.npy'

map_paths: ['city_image_1.npy', 'city_image_2.npy', city_image_3.npy]

n_agents: 10
n_targets: 20
n_jammers: 7
jamming_radius: 20 #This is radius, in comparison to comms_range. That is why it is a smaller value then comms_range, but looks bigger relitivly.  

seed: 0

generate_rand_map: true
# outer_border: null

# Example locations
# agent_positions:
#  - [200, 150]
#  - [200, 151]
#  - [200, 152]
#  - [200, 153]
#  - [200, 154]
#target_positions:
#- [18, 39]
#jammer_positions:
#  - [0, 0]

jammer_discovery_reward: 50
target_discovery_reward: 100
tracking_reward: 10
destruction_reward: 300
movement_penalty: -1
exploration_reward: 5