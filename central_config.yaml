env: custom_multi_agent_env
env_config:
  config_path: "config.yaml"
  render_mode: "human"  
num_workers: 1
framework: torch  
lr: 0.0003
train_batch_size: 4000
sgd_minibatch_size: 64
num_sgd_iter: 10
rollout_fragment_length: 200
batch_mode: truncate_episodes
num_gpus: 0
model:
  custom_model: centralised_critic_model  # Reference your custom centralized critic model
  custom_model_config:  # Custom model config section
    num_agents: 5  # Number of agents in your multi-agent environment
    obs_dim: 128  # Flattened observation dimension (e.g., 4*32)
    act_dim: 2  # Action dimension per agent (assumed to be continuous with 2 dimensions)
  conv_filters:
    - [32, [3, 3], 1]
    - [64, [3, 3], 1]
    - [128, [3, 3], 1]
  conv_activation: relu
local_dir: "./custom_ray_results"
logger_config:
  loggers: ["ray.tune.logger.TBXLogger"]
  logdir: "./custom_ray_results"
# multiagent:
#   policies:
#     policy_0:
#       - None
#       - Dict
#       - {
#           "encoded_map": {
#             "type": "box",
#             "low": -inf,
#             "high": inf,
#             "shape": [4,32]
#           },
#           "velocity": {
#             "type": "box",
#             "low": -30.0,
#             "high": 30.0,
#             "shape": [2]
#           },
#           "goal": {
#             "type": "box",
#             "low": -2000,
#             "high": 2000,
#             "shape": [2]
#           }
#         }
#       - {
#           "type": "box",
#           "low": -5,
#           "high": 5,
#           "shape": [2]
#         }
  # policy_mapping_fn: policy_mapping_fn